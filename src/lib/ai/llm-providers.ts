/**
 * LLM Providers Module - AI-Powered Financial Analysis Insights
 * 
 * This module demonstrates several important software engineering patterns and concepts:
 * 
 * 1. STRATEGY PATTERN: Multiple LLM providers (OpenAI, Mock) with common interface
 * 2. FACTORY PATTERN: LLMInsightService creates and manages provider instances
 * 3. SINGLETON PATTERN: Single service instance shared across the application
 * 4. CACHING PATTERN: In-memory cache to reduce API calls and improve performance
 * 5. FALLBACK PATTERN: Graceful degradation when primary services fail
 * 6. ADAPTER PATTERN: Unified interface for different LLM APIs
 * 
 * Key Learning Concepts:
 * - Interface segregation and polymorphism
 * - Error handling and resilience patterns
 * - API integration best practices
 * - Cost optimization through caching
 * - Type safety with TypeScript interfaces
 */

import { TechnicalAnalysisResult } from '@/lib/technical-analysis/types';

/**
 * LLMInsight Interface - Standardized AI Analysis Result
 * 
 * This interface defines the structure of insights generated by AI models.
 * It demonstrates several important TypeScript and API design concepts:
 * 
 * Design Principles:
 * - CONSISTENT STRUCTURE: All AI providers return the same format
 * - TYPE SAFETY: Union types ensure only valid values are used
 * - EXTENSIBILITY: Metadata object allows for provider-specific data
 * - TRACEABILITY: Provider field tracks which service generated the insight
 * 
 * @example
 * ```typescript
 * const insight: LLMInsight = {
 *   type: 'technical',
 *   content: 'RSI indicates overbought conditions...',
 *   confidence: 0.85,
 *   provider: 'openai',
 *   metadata: { indicators_used: ['RSI', 'MACD'] }
 * };
 * ```
 */
export interface LLMInsight {
  type: 'technical' | 'portfolio' | 'sentiment';    // Union type restricts to valid analysis types
  content: string;                                  // The actual AI-generated insight text
  confidence: number;                               // Confidence score (0-1) for insight reliability
  provider: 'openai' | 'bedrock' | 'cached';      // Which service generated this insight
  metadata: {                                       // Extensible metadata object
    indicators_used?: string[];                     // Optional: which technical indicators were analyzed
    timeframe?: string;                            // Optional: time period of analysis
    data_quality?: 'high' | 'medium' | 'low';     // Optional: input data quality assessment
    market_conditions?: string;                     // Optional: overall market context
    [key: string]: any;                            // Index signature: allows additional properties
  };
}

/**
 * LLMProvider Interface - Strategy Pattern Implementation
 * 
 * This interface demonstrates the STRATEGY PATTERN, one of the most important
 * design patterns in software engineering. It allows us to:
 * 
 * Benefits of Strategy Pattern:
 * - INTERCHANGEABLE ALGORITHMS: Swap between OpenAI, Bedrock, Mock providers
 * - OPEN/CLOSED PRINCIPLE: Add new providers without modifying existing code
 * - TESTABILITY: Easy to mock providers for unit testing
 * - RUNTIME FLEXIBILITY: Choose providers based on availability/cost
 * 
 * Interface Design Principles:
 * - MINIMAL SURFACE AREA: Only essential methods are exposed
 * - ASYNC BY DEFAULT: All operations return Promises for non-blocking execution
 * - CONSISTENT PARAMETERS: Same signature across all implementations
 * 
 * @example
 * ```typescript
 * // All providers implement the same interface
 * const openai: LLMProvider = new OpenAIProvider();
 * const mock: LLMProvider = new MockLLMProvider();
 * 
 * // Can be used interchangeably
 * const insight = await openai.generateInsight('technical', data, 'AAPL');
 * ```
 */
export interface LLMProvider {
  /**
   * Generate an AI insight for the given analysis type and data
   * 
   * @param type - Type of analysis: technical indicators, portfolio theory, or sentiment
   * @param data - Raw analysis data (technical indicators, portfolio metrics, etc.)
   * @param symbol - Stock symbol being analyzed (e.g., 'AAPL', 'GOOGL')
   * @returns Promise resolving to structured insight with confidence and metadata
   */
  generateInsight(
    type: 'technical' | 'portfolio' | 'sentiment',
    data: any,
    symbol: string
  ): Promise<LLMInsight>;

  /**
   * Check if this provider is currently available and configured
   * 
   * This method enables the CIRCUIT BREAKER pattern - we can check
   * provider health before attempting expensive API calls.
   * 
   * @returns Promise resolving to true if provider can be used
   */
  isAvailable(): Promise<boolean>;
}

/**
 * OpenAIProvider Class - Concrete Strategy Implementation
 * 
 * This class demonstrates several important patterns and concepts:
 * 
 * 1. STRATEGY PATTERN: Concrete implementation of LLMProvider interface
 * 2. DEPENDENCY INJECTION: API key can be injected via constructor or environment
 * 3. ENCAPSULATION: Private fields hide implementation details
 * 4. ERROR HANDLING: Comprehensive error handling for API failures
 * 5. HTTP CLIENT PATTERNS: Proper REST API integration with fetch()
 * 
 * Key Learning Points:
 * - How to integrate with external APIs securely
 * - Environment variable usage for configuration
 * - Async/await patterns for HTTP requests
 * - JSON serialization and deserialization
 * - Error propagation and handling strategies
 */
export class OpenAIProvider implements LLMProvider {
  private apiKey: string;                           // Private field - encapsulation principle
  private baseUrl = 'https://api.openai.com/v1';   // Constant base URL for OpenAI API

  /**
   * Constructor with Dependency Injection
   * 
   * This constructor demonstrates the DEPENDENCY INJECTION pattern:
   * - Allows API key to be provided explicitly (useful for testing)
   * - Falls back to environment variable (common in production)
   * - Provides empty string default (graceful degradation)
   * 
   * @param apiKey - Optional API key, falls back to environment variable
   */
  constructor(apiKey?: string) {
    // Dependency injection with fallback chain: parameter -> env var -> empty string
    this.apiKey = apiKey || process.env.OPENAI_API_KEY || '';
  }

  /**
   * Check if OpenAI provider is available
   * 
   * This method implements the CIRCUIT BREAKER pattern concept:
   * - Quick check before expensive API calls
   * - Prevents unnecessary network requests when misconfigured
   * - Uses JavaScript's "truthy" evaluation (!!) to convert string to boolean
   * 
   * @returns Promise<boolean> - true if API key is configured
   */
  async isAvailable(): Promise<boolean> {
    // Double negation (!!) converts truthy/falsy to explicit boolean
    // Empty string is falsy, non-empty string is truthy
    return !!this.apiKey;
  }

  /**
   * Generate AI insight using OpenAI's GPT model
   * 
   * This method demonstrates several important patterns:
   * 
   * 1. GUARD CLAUSES: Early validation and error throwing
   * 2. TEMPLATE METHOD: Structured approach with helper methods
   * 3. HTTP CLIENT PATTERN: Proper REST API integration
   * 4. ERROR HANDLING: Try-catch with logging and re-throwing
   * 5. OBJECT COMPOSITION: Building complex request objects
   * 
   * API Integration Best Practices:
   * - Always validate configuration before making requests
   * - Use appropriate HTTP headers (Authorization, Content-Type)
   * - Handle both network errors and API errors
   * - Log errors for debugging but don't expose sensitive data
   * - Use optional chaining (?.) for safe property access
   */
  async generateInsight(
    type: 'technical' | 'portfolio' | 'sentiment',
    data: any,
    symbol: string
  ): Promise<LLMInsight> {
    // GUARD CLAUSE: Validate configuration before proceeding
    if (!this.apiKey) {
      throw new Error('OpenAI API key not configured');
    }

    // TEMPLATE METHOD: Break complex operation into smaller, focused methods
    const prompt = this.buildPrompt(type, data, symbol);
    
    try {
      // HTTP CLIENT PATTERN: Structured API request with proper headers
      const response = await fetch(`${this.baseUrl}/chat/completions`, {
        method: 'POST',
        headers: {
          'Authorization': `Bearer ${this.apiKey}`,    // Bearer token authentication
          'Content-Type': 'application/json',          // Specify JSON payload
        },
        body: JSON.stringify({
          model: 'gpt-4o-mini',                        // Cost-effective model choice
          messages: [
            {
              role: 'system',                          // System prompt sets AI behavior
              content: this.getSystemPrompt(type)
            },
            {
              role: 'user',                            // User prompt contains actual data
              content: prompt
            }
          ],
          max_tokens: 500,                             // Limit response length for cost control
          temperature: 0.3,                           // Lower temperature = more consistent/focused responses
        }),
      });

      // ERROR HANDLING: Check HTTP status before processing response
      if (!response.ok) {
        throw new Error(`OpenAI API error: ${response.status} ${response.statusText}`);
      }

      // JSON DESERIALIZATION: Parse API response
      const result = await response.json();
      
      // SAFE PROPERTY ACCESS: Use optional chaining to prevent runtime errors
      const content = result.choices[0]?.message?.content || 'No insight generated';

      // OBJECT COMPOSITION: Build standardized response object
      return {
        type,
        content: content.trim(),                      // Remove whitespace
        confidence: this.calculateConfidence(data, type),  // Calculate confidence score
        provider: 'openai',                          // Track which provider generated this
        metadata: this.extractMetadata(data, type),  // Extract relevant metadata
      };

    } catch (error) {
      // ERROR HANDLING: Log for debugging, then re-throw for caller to handle
      console.error('OpenAI API error:', error);
      throw error;  // Re-throw to allow caller to implement fallback logic
    }
  }

  /**
   * Generate System Prompts for Different Analysis Types
   * 
   * This method demonstrates several important concepts:
   * 
   * 1. PROMPT ENGINEERING: Crafting effective AI instructions
   * 2. TEMPLATE PATTERN: Base prompt with specialized extensions
   * 3. SWITCH STATEMENT: Clean conditional logic for multiple cases
   * 4. STRING INTERPOLATION: Dynamic content insertion
   * 5. DOMAIN EXPERTISE: Financial analysis knowledge encoded in prompts
   * 
   * Prompt Engineering Best Practices:
   * - Set clear role and expertise level ("professional financial analyst")
   * - Provide specific instructions for output format and focus
   * - Include ethical guidelines (avoid direct investment advice)
   * - Use domain-specific terminology and concepts
   * - Structure prompts for consistency and clarity
   * 
   * @param type - The type of analysis to generate a system prompt for
   * @returns Specialized system prompt for the AI model
   */
  private getSystemPrompt(type: 'technical' | 'portfolio' | 'sentiment'): string {
    // BASE TEMPLATE: Common instructions for all analysis types
    const basePrompt = `You are a professional financial analyst with expertise in ${type} analysis. 
    Provide clear, actionable insights based on the data provided. 
    Be concise but thorough, focusing on practical implications for investors.
    Avoid giving direct investment advice - instead explain what the data suggests.`;

    // SPECIALIZED PROMPTS: Each analysis type gets specific focus areas
    switch (type) {
      case 'technical':
        // Technical analysis focuses on price patterns and indicators
        return `${basePrompt}
        
        Focus on:
        - Chart patterns and technical indicator signals
        - Support and resistance levels
        - Momentum and trend analysis
        - Volume patterns and their significance
        - Risk levels and potential entry/exit points`;

      case 'portfolio':
        // Portfolio analysis focuses on risk-adjusted returns and diversification
        return `${basePrompt}
        
        Focus on:
        - Risk-adjusted returns and portfolio metrics
        - Correlation analysis and diversification benefits
        - Position sizing recommendations
        - Risk management implications
        - Portfolio optimization insights`;

      case 'sentiment':
        // Sentiment analysis focuses on market psychology and behavioral factors
        return `${basePrompt}
        
        Focus on:
        - Market sentiment indicators and their reliability
        - News and social media impact analysis
        - Institutional vs retail sentiment differences
        - Sentiment divergences and contrarian signals
        - Overall market mood and its implications`;

      default:
        // DEFENSIVE PROGRAMMING: Handle unexpected cases gracefully
        return basePrompt;
    }
  }

  /**
   * Build User Prompts with Actual Data
   * 
   * This method demonstrates the FACTORY METHOD pattern:
   * - Single entry point that delegates to specialized builders
   * - Each prompt type has its own construction logic
   * - Consistent interface but different implementations
   * 
   * Design Benefits:
   * - SINGLE RESPONSIBILITY: Each builder focuses on one prompt type
   * - EXTENSIBILITY: Easy to add new prompt types
   * - MAINTAINABILITY: Changes to one type don't affect others
   * - TESTABILITY: Each builder can be tested independently
   * 
   * @param type - Type of analysis prompt to build
   * @param data - Analysis data to include in prompt
   * @param symbol - Stock symbol being analyzed
   * @returns Formatted prompt string with actual data
   */
  private buildPrompt(type: 'technical' | 'portfolio' | 'sentiment', data: any, symbol: string): string {
    // FACTORY METHOD: Delegate to specialized prompt builders
    switch (type) {
      case 'technical':
        return this.buildTechnicalPrompt(data, symbol);
      case 'portfolio':
        return this.buildPortfolioPrompt(data, symbol);
      case 'sentiment':
        return this.buildSentimentPrompt(data, symbol);
      default:
        // FALLBACK: Generic prompt for unexpected types
        return `Analyze the following data for ${symbol}:\n${JSON.stringify(data, null, 2)}`;
    }
  }

  /**
   * Build Technical Analysis Prompt with Real Data
   * 
   * This method demonstrates several advanced JavaScript/TypeScript concepts:
   * 
   * 1. OPTIONAL CHAINING (?.): Safe property access that won't throw errors
   * 2. ARRAY INDEXING: Getting the latest values from time series data
   * 3. TEMPLATE LITERALS: Multi-line string formatting with embedded expressions
   * 4. CONDITIONAL RENDERING: Only show indicators that have data
   * 5. FUNCTIONAL PROGRAMMING: Using map() and slice() for data transformation
   * 6. NUMBER FORMATTING: Using toFixed() for consistent decimal places
   * 
   * Data Processing Patterns:
   * - Extract latest values from time series arrays
   * - Handle missing data gracefully with optional chaining
   * - Format numbers for human readability
   * - Structure data in logical sections for AI consumption
   * 
   * @param analysis - Complete technical analysis results
   * @param symbol - Stock symbol being analyzed
   * @returns Formatted prompt with technical indicator data
   */
  private buildTechnicalPrompt(analysis: TechnicalAnalysisResult, symbol: string): string {
    // EXTRACT LATEST VALUES: Get the most recent indicator values from time series
    // Using optional chaining (?.) to safely access potentially undefined arrays
    const latest = {
      rsi: analysis.indicators.rsi?.[analysis.indicators.rsi.length - 1],
      macd: analysis.indicators.macd?.[analysis.indicators.macd.length - 1],
      bb: analysis.indicators.bollingerBands?.[analysis.indicators.bollingerBands.length - 1],
      stochastic: analysis.indicators.stochastic?.[analysis.indicators.stochastic.length - 1],
      williamsR: analysis.indicators.williamsR?.[analysis.indicators.williamsR.length - 1],
    };

    // TEMPLATE LITERAL: Multi-line string with embedded expressions
    // This creates a structured prompt that the AI can easily parse and understand
    return `Analyze the technical indicators for ${symbol}:

CURRENT TECHNICAL STATE:
- Overall Sentiment: ${analysis.summary.overall} (${Math.round(analysis.summary.strength * 100)}% strength)
- Trend Direction: ${analysis.summary.trendDirection}
- Momentum: ${analysis.summary.momentum}
- Volatility: ${analysis.summary.volatility}

TECHNICAL INDICATORS:
${latest.rsi ? `- RSI: ${latest.rsi.value.toFixed(1)} (Overbought: ${latest.rsi.overbought}, Oversold: ${latest.rsi.oversold})` : ''}
${latest.macd ? `- MACD: ${latest.macd.macd.toFixed(2)}, Signal: ${latest.macd.signal.toFixed(2)}, Histogram: ${latest.macd.histogram.toFixed(2)}` : ''}
${latest.bb ? `- Bollinger Bands %B: ${(latest.bb.percentB * 100).toFixed(1)}%, Squeeze: ${latest.bb.squeeze}` : ''}
${latest.stochastic ? `- Stochastic: %K=${latest.stochastic.k.toFixed(1)}, %D=${latest.stochastic.d.toFixed(1)}` : ''}
${latest.williamsR ? `- Williams %R: ${latest.williamsR.value.toFixed(1)}` : ''}

TRADING SIGNALS (${analysis.signals.length} total):
${analysis.signals.slice(0, 5).map(s => `- ${s.indicator}: ${s.signal.toUpperCase()} (${Math.round(s.strength * 100)}% strength) - ${s.description}`).join('\n')}

Please provide a comprehensive technical analysis explaining:
1. What these indicators collectively suggest about the stock's current state
2. Key support/resistance levels and trend analysis
3. Momentum and volatility implications
4. Potential trading opportunities and risks
5. What to watch for in the near term`;
  }

  private buildPortfolioPrompt(data: any, symbol: string): string {
    // This would include portfolio metrics when available
    return `Analyze the portfolio implications for ${symbol}:

PORTFOLIO CONTEXT:
- Symbol: ${symbol}
- Analysis Type: Portfolio Theory Metrics

Please provide insights on:
1. Risk-adjusted return potential
2. Correlation and diversification benefits
3. Optimal position sizing considerations
4. Risk management implications
5. Portfolio optimization recommendations

Note: This is a simplified analysis. Full portfolio metrics will be available when multiple holdings are analyzed together.`;
  }

  private buildSentimentPrompt(data: any, symbol: string): string {
    // This would include sentiment data when available
    return `Analyze the market sentiment for ${symbol}:

SENTIMENT CONTEXT:
- Symbol: ${symbol}
- Analysis Type: Market Sentiment Analysis

Please provide insights on:
1. Overall market sentiment and investor mood
2. Potential sentiment-driven price movements
3. Contrarian vs momentum opportunities
4. Risk factors from sentiment extremes
5. How sentiment aligns with technical analysis

Note: This analysis is based on technical patterns that often reflect underlying sentiment. Direct sentiment data integration is planned for future updates.`;
  }

  /**
   * Calculate Confidence Score for AI Insights
   * 
   * This method demonstrates several important programming concepts:
   * 
   * 1. HEURISTIC ALGORITHMS: Using rules of thumb to estimate confidence
   * 2. MATHEMATICAL FUNCTIONS: Math.min/max for boundary constraints
   * 3. FUNCTIONAL PROGRAMMING: Using reduce() for array aggregation
   * 4. DEFENSIVE PROGRAMMING: Providing sensible defaults
   * 5. TYPE GUARDS: Checking data structure before processing
   * 
   * Confidence Calculation Logic:
   * - More signals = higher confidence (up to a point)
   * - Higher average signal strength = higher confidence
   * - Bounded between 0.3 and 0.95 to avoid extremes
   * - Default to 0.7 for unknown data types
   * 
   * @param data - Analysis data to assess
   * @param type - Type of analysis being performed
   * @returns Confidence score between 0 and 1
   */
  private calculateConfidence(data: any, type: string): number {
    // HEURISTIC CALCULATION: Estimate confidence based on data quality
    if (type === 'technical' && data.signals) {
      const signalCount = data.signals.length;
      
      // FUNCTIONAL PROGRAMMING: Use reduce to calculate average signal strength
      const avgStrength = data.signals.reduce((sum: number, s: any) => sum + s.strength, 0) / signalCount;
      
      // MATHEMATICAL BOUNDS: Constrain confidence to reasonable range
      // Formula: average strength * signal density factor, bounded between 0.3 and 0.95
      return Math.min(0.95, Math.max(0.3, avgStrength * (signalCount / 10)));
    }
    
    // DEFAULT VALUE: Reasonable confidence for unknown data types
    return 0.7;
  }

  /**
   * Extract Metadata from Analysis Data
   * 
   * This method demonstrates:
   * 
   * 1. OBJECT COMPOSITION: Building metadata objects dynamically
   * 2. CONDITIONAL LOGIC: Different metadata for different analysis types
   * 3. ARRAY FILTERING: Finding indicators with actual data
   * 4. OPTIONAL CHAINING: Safe property access with fallbacks
   * 5. FUNCTIONAL PROGRAMMING: Using filter() for array processing
   * 
   * Metadata serves multiple purposes:
   * - Traceability: Track which indicators were used
   * - Quality assessment: Indicate data completeness
   * - Context: Provide additional information for debugging
   * - Extensibility: Allow for future metadata fields
   * 
   * @param data - Analysis data to extract metadata from
   * @param type - Type of analysis being performed
   * @returns Metadata object with relevant information
   */
  private extractMetadata(data: any, type: string): any {
    // BASE METADATA: Common fields for all analysis types
    const metadata: any = {
      timeframe: '1D',           // Default timeframe
      data_quality: 'high',      // Assume high quality unless proven otherwise
    };

    // TYPE-SPECIFIC METADATA: Add relevant fields based on analysis type
    if (type === 'technical' && data.indicators) {
      // FUNCTIONAL PROGRAMMING: Filter to find indicators with actual data
      metadata.indicators_used = Object.keys(data.indicators).filter(key => 
        data.indicators[key] &&                    // Indicator exists
        Array.isArray(data.indicators[key]) &&     // Is an array
        data.indicators[key].length > 0            // Has data points
      );
      
      // OPTIONAL CHAINING: Safe access with fallback
      metadata.market_conditions = data.summary?.overall || 'neutral';
    }

    return metadata;
  }
}

/**
 * MockLLMProvider Class - Fallback Strategy Implementation
 * 
 * This class demonstrates several important software engineering patterns:
 * 
 * 1. FALLBACK PATTERN: Provides service when primary providers fail
 * 2. NULL OBJECT PATTERN: Returns valid responses instead of errors
 * 3. TEMPLATE RESPONSES: Pre-written content for different scenarios
 * 4. GRACEFUL DEGRADATION: System continues working even when AI is unavailable
 * 5. TESTING SUPPORT: Predictable responses for unit tests
 * 
 * Use Cases:
 * - Development environments without API keys
 * - Production fallback when external services fail
 * - Unit testing with predictable responses
 * - Cost control by avoiding unnecessary API calls
 * - Offline operation capabilities
 * 
 * Design Benefits:
 * - RELIABILITY: System never completely fails due to external dependencies
 * - COST CONTROL: No API charges for fallback responses
 * - PREDICTABILITY: Consistent responses for testing
 * - PERFORMANCE: Instant responses without network calls
 */
export class MockLLMProvider implements LLMProvider {
  /**
   * Mock provider is always available
   * 
   * This ensures the fallback provider can always be used,
   * implementing the NULL OBJECT PATTERN where we provide
   * a working implementation instead of null/undefined.
   */
  async isAvailable(): Promise<boolean> {
    return true;  // Always available - that's the point of a fallback!
  }

  /**
   * Generate mock insights with template responses
   * 
   * This method demonstrates:
   * 
   * 1. TEMPLATE PATTERN: Pre-written responses with dynamic content
   * 2. STRING INTERPOLATION: Inserting dynamic values into templates
   * 3. OPTIONAL CHAINING: Safe property access with fallbacks
   * 4. OBJECT LITERAL: Clean way to organize related data
   * 5. CONSISTENT INTERFACE: Same return type as real providers
   * 
   * The mock responses are designed to:
   * - Sound professional and realistic
   * - Include dynamic data when available
   * - Provide useful fallback information
   * - Maintain the same structure as real AI responses
   */
  async generateInsight(
    type: 'technical' | 'portfolio' | 'sentiment',
    data: any,
    symbol: string
  ): Promise<LLMInsight> {
    // TEMPLATE RESPONSES: Pre-written insights for each analysis type
    // These templates include dynamic content insertion using template literals
    const mockInsights = {
      technical: `Technical analysis for ${symbol} shows mixed signals. The current trend appears ${data.summary?.trendDirection || 'sideways'} with ${data.summary?.volatility || 'medium'} volatility. Key indicators suggest monitoring for potential breakout opportunities while managing risk through proper position sizing.`,
      
      portfolio: `From a portfolio perspective, ${symbol} exhibits characteristics that suggest careful position sizing is warranted. Consider the stock's correlation with existing holdings and overall portfolio risk when determining allocation size.`,
      
      sentiment: `Market sentiment for ${symbol} appears to be in a transitional phase. Current technical patterns suggest investor uncertainty, which could present opportunities for patient investors with proper risk management.`
    };

    // CONSISTENT RESPONSE STRUCTURE: Same format as real providers
    return {
      type,
      content: mockInsights[type],           // Template response with dynamic content
      confidence: 0.6,                      // Moderate confidence for mock data
      provider: 'cached',                   // Indicate this is a fallback response
      metadata: {
        indicators_used: ['RSI', 'MACD', 'Bollinger Bands'],  // Common indicators
        timeframe: '1D',                    // Standard timeframe
        data_quality: 'medium',             // Conservative quality assessment
        market_conditions: data.summary?.overall || 'neutral',  // Use real data if available
      },
    };
  }
}

/**
 * LLMInsightService Class - Service Layer with Multiple Patterns
 * 
 * This class is an excellent example of several advanced software engineering patterns:
 * 
 * 1. SERVICE LAYER PATTERN: High-level interface for complex operations
 * 2. CHAIN OF RESPONSIBILITY: Try providers in order until one succeeds
 * 3. CACHING PATTERN: In-memory cache to reduce API calls and improve performance
 * 4. CIRCUIT BREAKER: Check provider availability before attempting calls
 * 5. FACADE PATTERN: Simple interface hiding complex provider management
 * 6. SINGLETON PATTERN: Single service instance (implemented at module level)
 * 
 * Key Benefits:
 * - PERFORMANCE: Caching reduces redundant API calls
 * - RELIABILITY: Multiple providers ensure service availability
 * - COST OPTIMIZATION: Cache prevents expensive duplicate requests
 * - SIMPLICITY: Single interface for complex multi-provider logic
 * - EXTENSIBILITY: Easy to add new providers or caching strategies
 */
export class LLMInsightService {
  private providers: LLMProvider[];                                    // Array of available providers
  private cache: Map<string, { insight: LLMInsight; timestamp: number }> = new Map();  // In-memory cache
  private cacheTimeout = 30 * 60 * 1000;                             // 30 minutes in milliseconds

  /**
   * Constructor - Initialize Service with Provider Chain
   * 
   * This constructor demonstrates the CHAIN OF RESPONSIBILITY pattern:
   * - Providers are tried in order (OpenAI first, Mock as fallback)
   * - First available provider handles the request
   * - Fallback ensures the service never completely fails
   * 
   * Design Decisions:
   * - OpenAI first: Best quality insights when available
   * - Mock last: Always available fallback
   * - Array order matters: Determines priority
   */
  constructor() {
    // CHAIN OF RESPONSIBILITY: Providers in priority order
    this.providers = [
      new OpenAIProvider(),      // Primary provider (best quality)
      new MockLLMProvider(),     // Fallback provider (always available)
    ];
  }

  /**
   * Generate AI Insight with Caching and Fallback Logic
   * 
   * This method demonstrates several advanced patterns and concepts:
   * 
   * 1. CACHING PATTERN: Check cache before expensive operations
   * 2. CHAIN OF RESPONSIBILITY: Try providers until one succeeds
   * 3. CIRCUIT BREAKER: Check availability before attempting calls
   * 4. ERROR HANDLING: Graceful degradation with logging
   * 5. CACHE KEY GENERATION: Create unique identifiers for cache entries
   * 6. TIME-BASED EXPIRATION: Automatic cache invalidation
   * 
   * Performance Optimizations:
   * - Cache hit: Return immediately without API calls
   * - Provider availability check: Avoid doomed requests
   * - Error isolation: One provider failure doesn't break the chain
   * - Automatic caching: Store successful results for future use
   * 
   * @param type - Type of analysis to generate
   * @param data - Analysis data to process
   * @param symbol - Stock symbol being analyzed
   * @returns Promise resolving to AI-generated insight
   */
  async generateInsight(
    type: 'technical' | 'portfolio' | 'sentiment',
    data: any,
    symbol: string
  ): Promise<LLMInsight> {
    // CACHE KEY GENERATION: Create unique identifier for this request
    // Includes symbol, type, and partial data hash for uniqueness
    const cacheKey = `${symbol}-${type}-${JSON.stringify(data).slice(0, 100)}`;
    
    // CACHE CHECK: Look for existing result before expensive operations
    const cached = this.cache.get(cacheKey);
    if (cached && Date.now() - cached.timestamp < this.cacheTimeout) {
      // CACHE HIT: Return cached result immediately
      return cached.insight;
    }

    // CHAIN OF RESPONSIBILITY: Try each provider until one succeeds
    for (const provider of this.providers) {
      try {
        // CIRCUIT BREAKER: Check if provider is available before attempting
        if (await provider.isAvailable()) {
          // ATTEMPT GENERATION: Try to get insight from this provider
          const insight = await provider.generateInsight(type, data, symbol);
          
          // CACHE STORAGE: Store successful result for future requests
          this.cache.set(cacheKey, {
            insight,                    // The actual insight data
            timestamp: Date.now(),      // When this was cached (for expiration)
          });
          
          // SUCCESS: Return the generated insight
          return insight;
        }
      } catch (error) {
        // ERROR HANDLING: Log error but continue to next provider
        console.error(`Provider failed for ${type} insight:`, error);
        // Continue to next provider in the chain
      }
    }

    // COMPLETE FAILURE: All providers failed (should be rare with MockLLMProvider)
    throw new Error('All LLM providers failed');
  }

  /**
   * Generate All Three Types of Insights Concurrently
   * 
   * This method demonstrates several advanced asynchronous programming patterns:
   * 
   * 1. CONCURRENT EXECUTION: Promise.allSettled() runs all requests in parallel
   * 2. ERROR ISOLATION: One failed insight doesn't prevent others from succeeding
   * 3. GRACEFUL DEGRADATION: Failed insights get fallback responses
   * 4. PERFORMANCE OPTIMIZATION: Parallel execution is faster than sequential
   * 5. RESULT AGGREGATION: Combine multiple async results into single response
   * 6. TYPE SAFETY: Return type explicitly defines the expected structure
   * 
   * Promise.allSettled() vs Promise.all():
   * - Promise.all(): Fails fast - if any promise rejects, entire operation fails
   * - Promise.allSettled(): Waits for all - returns results and errors separately
   * - allSettled() is better for independent operations where partial success is acceptable
   * 
   * Performance Benefits:
   * - 3 insights generated in parallel instead of sequentially
   * - Total time â‰ˆ slowest individual request (not sum of all requests)
   * - Better user experience with faster response times
   * 
   * @param analysis - Complete technical analysis results
   * @param symbol - Stock symbol being analyzed
   * @returns Promise resolving to all three insight types
   */
  async generateAllInsights(analysis: TechnicalAnalysisResult, symbol: string): Promise<{
    technical: LLMInsight;
    portfolio: LLMInsight;
    sentiment: LLMInsight;
  }> {
    // CONCURRENT EXECUTION: Start all three insight generations simultaneously
    // Promise.allSettled() waits for all promises to complete (success or failure)
    const [technical, portfolio, sentiment] = await Promise.allSettled([
      this.generateInsight('technical', analysis, symbol),
      this.generateInsight('portfolio', analysis, symbol),
      this.generateInsight('sentiment', analysis, symbol),
    ]);

    // RESULT AGGREGATION: Combine results with fallback handling
    // For each insight, use the successful result or generate a fallback
    return {
      // CONDITIONAL ASSIGNMENT: Use successful result or fallback
      technical: technical.status === 'fulfilled' 
        ? technical.value 
        : await new MockLLMProvider().generateInsight('technical', analysis, symbol),
      
      portfolio: portfolio.status === 'fulfilled' 
        ? portfolio.value 
        : await new MockLLMProvider().generateInsight('portfolio', analysis, symbol),
      
      sentiment: sentiment.status === 'fulfilled' 
        ? sentiment.value 
        : await new MockLLMProvider().generateInsight('sentiment', analysis, symbol),
    };
  }
}

/**
 * Singleton Pattern Implementation
 * 
 * This code demonstrates the SINGLETON PATTERN, which ensures only one instance
 * of a class exists throughout the application lifecycle. This is particularly
 * important for services that maintain state (like caches) or expensive resources.
 * 
 * Why Singleton for LLMInsightService?
 * 1. CACHE SHARING: All parts of the app share the same cache
 * 2. RESOURCE EFFICIENCY: Avoid creating multiple provider instances
 * 3. CONFIGURATION CONSISTENCY: Single point of configuration
 * 4. MEMORY OPTIMIZATION: One cache instead of many
 * 5. LAMBDA OPTIMIZATION: Reuse instances across Lambda invocations
 * 
 * Implementation Details:
 * - Module-level variable holds the single instance
 * - Lazy initialization: Instance created on first access
 * - Thread-safe in Node.js (single-threaded event loop)
 * - Memory efficient: Instance persists across function calls
 * 
 * Alternative Patterns:
 * - Dependency Injection: Pass service instance to consumers
 * - Factory Pattern: Create instances with specific configurations
 * - Service Locator: Registry of service instances
 * 
 * This singleton approach is simple and effective for this use case.
 */

// SINGLETON STORAGE: Module-level variable holds the single instance
let insightService: LLMInsightService | null = null;

/**
 * Get Singleton Instance of LLMInsightService
 * 
 * This function implements the classic singleton pattern:
 * 1. Check if instance already exists
 * 2. If not, create new instance
 * 3. Return the instance (existing or newly created)
 * 
 * Benefits:
 * - LAZY INITIALIZATION: Instance created only when needed
 * - MEMORY EFFICIENCY: Only one instance ever exists
 * - CACHE PERSISTENCE: Cache survives across function calls
 * - SIMPLE API: Easy to use from anywhere in the application
 * 
 * Usage Examples:
 * ```typescript
 * // From API routes
 * const service = getLLMInsightService();
 * const insight = await service.generateInsight('technical', data, 'AAPL');
 * 
 * // From React components (via API)
 * const insights = await service.generateAllInsights(analysis, symbol);
 * ```
 * 
 * @returns Singleton instance of LLMInsightService
 */
export function getLLMInsightService(): LLMInsightService {
  // LAZY INITIALIZATION: Create instance only if it doesn't exist
  if (!insightService) {
    insightService = new LLMInsightService();
  }
  
  // RETURN SINGLETON: Always return the same instance
  return insightService;
}